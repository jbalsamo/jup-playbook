{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python tests\n",
    "\n",
    "First we need to import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can initalize the Azure OpenAI client. This will allow us to connect to the Azure OpenAI model and get completions.\n",
    "\n",
    "We need to set the following environment variables:\n",
    "\n",
    "- AZURE_OPENAI_API_KEY\n",
    "- AZURE_OPENAI_ENDPOINT\n",
    "- AZURE_OPENAI_MODEL_VERSION\n",
    "\n",
    "For this we will use dotenv to load the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can create a chat completion function to use on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to connect to Azure OpenAI model\n",
    "def get_completion(prompt, model=\"gpt-4.1\"):\n",
    "    \"\"\"\n",
    "    Get completion from Azure OpenAI model\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the connection to the Azure OpenAI model.\n",
    "\n",
    "Edit your prompt to test the connection to the Azure OpenAI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<input type=\"text\" name=\"name\" id=\"name\" value=\"John Doe\">\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262b1518e83d430ba06378563f651ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Give me icd 10 codes for diabetes.', description='Question:', layout=Layout(height='75px', padding…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a text input widget\n",
    "query_input = widgets.Text(\n",
    "    value='Give me icd 10 codes for diabetes.',\n",
    "    placeholder='Type your query',\n",
    "    description='Question:',\n",
    "    layout=widgets.Layout(width=\"80%\", height=\"75px\",padding=\"10px\")\n",
    ")\n",
    "\n",
    "# Display the widget in the cell\n",
    "display(query_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ICD-10 Code | SNOMED Code | Description                                           |\n",
      "|-------------|-------------|------------------------------------------------------|\n",
      "| E10         | 46635009    | Type 1 diabetes mellitus                             |\n",
      "| E11         | 44054006    | Type 2 diabetes mellitus                             |\n",
      "| E13         | 58718002    | Other specified diabetes mellitus                    |\n",
      "| E14         | 73211009    | Unspecified diabetes mellitus                        |\n",
      "\n",
      "### Exclusions & Rationale\n",
      "- Gestational diabetes (ICD-10: O24) and neonatal diabetes (ICD-10: P70.2, P70.3) were excluded as requested.\n",
      "- Subcategories (e.g., E10.1, E11.2) were not listed individually for brevity, as the question requested general codes and descriptions.\n",
      "- No records excluded due to missing values or duplication.\n",
      "- No invented values; all SNOMED codes and descriptions verified.\n"
     ]
    }
   ],
   "source": [
    "def build_prompt(question: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a careful analyst. Follow the instructions precisely.\n",
    "\n",
    "# Input\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "# Goal\n",
    "- Answer the question by producing a table that contains **exactly** the fields requested in the question (and only those fields, in that order).\n",
    "- After the table, provide a short prose section titled **\"Exclusions & Rationale\"** that explains which records were excluded and why.\n",
    "\n",
    "# Output Format (strict)\n",
    "1) First, output a Markdown table with a header row. The columns must match the requested fields **exactly** (names and order).\n",
    "2) Then output the section:\n",
    "   ### Exclusions & Rationale\n",
    "   - Briefly describe any records considered but excluded, with concrete reasons (e.g., missing required field, outside date range, duplicate, low confidence, conflicting source, not matching filters).\n",
    "   - If nothing was excluded, state: \"No records excluded.\"\n",
    "\n",
    "# Rules\n",
    "- Do **not** add extra columns or derived fields unless explicitly requested. If the question is ambiguous about fields, infer the minimal set and clearly state the assumption in **Exclusions & Rationale**.\n",
    "- Do **not** fabricate or guess values. If a specific field value is unavailable, leave the cell blank and explain the gap in **Exclusions & Rationale**.\n",
    "- Ensure consistent units, formats, and identifiers across the table (dates, currencies, IDs).\n",
    "- If no records match, output a header-only empty table (with the requested columns) and explain why no records qualified.\n",
    "- Remove duplicates; if deduping occurred, explain your approach in **Exclusions & Rationale**.\n",
    "- If the question implies filters (time ranges, categories, thresholds), apply them and mention them in **Exclusions & Rationale**.\n",
    "\n",
    "# Reflective Check (do this before finalizing)\n",
    "- Column names exactly match the requested fields and are in the correct order.\n",
    "- Every row adheres to all implied/explicit filters from the question.\n",
    "- No invented values; blanks are used where data is missing and reasons are documented.\n",
    "- No duplicates; totals and counts (if present) are internally consistent.\n",
    "- Units and formats are uniform (e.g., ISO-8601 dates, consistent currency symbols).\n",
    "- The **Exclusions & Rationale** section clearly lists exclusion reasons or states none.\n",
    "\n",
    "# Final Deliverable\n",
    "Return only:\n",
    "1) The Markdown table.\n",
    "2) The \"### Exclusions & Rationale\" section.\n",
    "No additional commentary.\n",
    "\"\"\"\n",
    "\n",
    "my_prompt: str = build_prompt(query_input.value)\n",
    "\n",
    "response = get_completion(my_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These results are run against gpt-4.1 without any system prompt or RAG data. Add those to this could yield better results, while requiring more work on the naitenance side.\n",
    "\n",
    "### Now we need to try a more complex task. A chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f1b7b6477e41bbbd80dce26b106847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value=\"<h3 style='margin:0 0 6px 0;'>Output format</h3>\"), RadioButtons(opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chat UI in Jupyter powered by Azure OpenAI + .env\n",
    "# !pip install openai python-dotenv ipywidgets\n",
    "\n",
    "import os, html, textwrap\n",
    "from dotenv import load_dotenv\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, Textarea, Button, HTML, Layout, RadioButtons, Label\n",
    ")\n",
    "from IPython.display import display\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# --- Load environment variables (expects a .env file next to your notebook) ---\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_API_KEY   = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT  = os.getenv(\"AZURE_OPENAI_ENDPOINT\")   # e.g. https://my-res.openai.azure.com/\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_MODEL_VERSION\")  # e.g. 2024-10-21\n",
    "AZURE_OPENAI_DEPLOYMENT  = os.getenv(\"AZURE_DEPLOYMENT_NAME\")   # your deployment name (not the model family)\n",
    "# Chat UI with sidebar format selector + prompt template (Azure OpenAI)\n",
    "# !pip install openai python-dotenv ipywidgets\n",
    "\n",
    "if not all([AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_VERSION, AZURE_OPENAI_DEPLOYMENT]):\n",
    "    raise RuntimeError(\"Missing one or more Azure OpenAI ENV VARS.\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "# --- UI: sidebar + main ---\n",
    "format_picker = RadioButtons(\n",
    "    options=[(\"CSV (default)\", \"csv\"), (\"JSON\", \"json\"), (\"Markdown\", \"markdown\")],\n",
    "    value=\"csv\"\n",
    ")\n",
    "sidebar = VBox(\n",
    "    [\n",
    "        HTML(\"<h3 style='margin:0 0 6px 0;'>Output format</h3>\"),\n",
    "        format_picker,\n",
    "        HTML(\"<small>Result will include a brief prose explanation of what was included/excluded.</small>\")\n",
    "    ],\n",
    "    layout=Layout(width=\"260px\", padding=\"10px\", border=\"1px solid #eee\")\n",
    ")\n",
    "\n",
    "chat_log = VBox(layout=Layout(border='1px solid #ddd', padding='8px', height='420px', overflow_y='auto', flex='1'))\n",
    "user_input = Textarea(\n",
    "    placeholder='Ask a question or request an analysis…',\n",
    "    layout=Layout(width='100%', height='90px', resize='vertical')\n",
    ")\n",
    "send_btn = Button(description='Send', layout=Layout(width='120px', height='40px'))\n",
    "clear_btn = Button(description='Clear', layout=Layout(width='120px', height='40px'))\n",
    "controls = HBox([send_btn, clear_btn])\n",
    "\n",
    "main = VBox([chat_log, user_input, controls], layout=Layout(flex='1'))\n",
    "app = HBox([sidebar, main], layout=Layout(gap=\"12px\"))\n",
    "\n",
    "# --- Message helpers ---\n",
    "def add_message(role, text):\n",
    "    safe = html.escape(text).replace('\\n', '<br>')\n",
    "    color = '#eef6ff' if role == 'user' else '#f6f6f6'\n",
    "    align = 'flex-end' if role == 'user' else 'flex-start'\n",
    "    bubble = HTML(\n",
    "        value=f\"\"\"\n",
    "        <div style=\"display:flex; justify-content:{align};\">\n",
    "          <div style=\"\n",
    "            max-width: 90%;\n",
    "            margin: 6px 0;\n",
    "            padding: 10px 12px;\n",
    "            border-radius: 14px;\n",
    "            background:{color};\n",
    "            border:1px solid #e5e5e5;\n",
    "            font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;\n",
    "            font-size: 14px; line-height: 1.45;\">\n",
    "            <b style=\"opacity:.6\">{'You' if role=='user' else 'Bot'}</b><br>{safe}\n",
    "          </div>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        layout=Layout(width='100%')\n",
    "    )\n",
    "    chat_log.children = (*chat_log.children, bubble)\n",
    "\n",
    "# --- Prompt template (format-aware) ---\n",
    "def build_messages(user_question: str, chosen_format: str):\n",
    "    \"\"\"\n",
    "    Template goals:\n",
    "      1) Answer the user's question.\n",
    "      2) Produce results in the chosen format (csv/json/markdown).\n",
    "      3) Always include a short prose explanation of inclusion/exclusion criteria.\n",
    "      4) Perform an internal reflective quality check; correct errors before answering.\n",
    "         Do not reveal internal reasoning—only provide the final answer.\n",
    "    \"\"\"\n",
    "    # Normalize label for instructions\n",
    "    fmt_label = chosen_format.upper()\n",
    "    # Simple, explicit directions for structure\n",
    "    format_instructions = {\n",
    "        \"csv\": textwrap.dedent(\"\"\"\\\n",
    "            Output Format: CSV\n",
    "            - Provide ONLY one CSV block for the results with a single header row.\n",
    "            - Use commas as separators; escape commas/newlines/quotes correctly.\n",
    "            - After the CSV block, include a short prose paragraph titled \"Explanation\".\n",
    "        \"\"\"),\n",
    "        \"json\": textwrap.dedent(\"\"\"\\\n",
    "            Output Format: JSON\n",
    "            - Provide ONLY one valid JSON object or array for the results.\n",
    "            - Ensure valid JSON (proper quotes, no trailing commas).\n",
    "            - After the JSON, include a short prose paragraph titled \"Explanation\".\n",
    "        \"\"\"),\n",
    "        \"markdown\": textwrap.dedent(\"\"\"\\\n",
    "            Output Format: Markdown\n",
    "            - Provide results as a well-formed Markdown table (with a header row).\n",
    "            - After the table, include a short prose paragraph titled \"Explanation\".\n",
    "        \"\"\"),\n",
    "    }[chosen_format]\n",
    "\n",
    "    system_prompt = textwrap.dedent(\"\"\"\\\n",
    "        You are a meticulous analyst. Be concise and accurate. When asked to output in a specific format,\n",
    "        strictly follow that format. Always include a short prose explanation of inclusion/exclusion\n",
    "        decisions. Perform an internal reflective quality check to avoid errors and correct them before\n",
    "        producing the final answer. Do NOT reveal your internal reasoning; provide only the final answer.\n",
    "    \"\"\")\n",
    "\n",
    "    user_prompt = textwrap.dedent(f\"\"\"\\\n",
    "        User Question:\n",
    "        {user_question}\n",
    "\n",
    "        Requirements:\n",
    "        - Answer the question.\n",
    "        - Produce results in {fmt_label} as specified below.\n",
    "        - Always include a prose \"Explanation\" describing why certain results were included or excluded.\n",
    "        - Perform a reflective quality check; correct any mistakes silently before finalizing.\n",
    "\n",
    "        {format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "def call_azure_openai(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,  # deployment name\n",
    "        messages=messages,\n",
    "        temperature=0.2,                 # lower temp for more deterministic, schema-friendly output\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# --- Event handlers ---\n",
    "def handle_send(_=None):\n",
    "    text = user_input.value.strip()\n",
    "    if not text:\n",
    "        return\n",
    "    send_btn.disabled = True\n",
    "    try:\n",
    "        # Show user message (with format selection summary)\n",
    "        fmt = format_picker.value\n",
    "        add_message('user', f\"{text}\\n\\n[Requested format: {fmt.upper()}]\")\n",
    "\n",
    "        # Build messages with format-aware template\n",
    "        msgs = build_messages(text, fmt)\n",
    "\n",
    "        # Call model\n",
    "        reply = call_azure_openai(msgs)\n",
    "\n",
    "        # Show bot reply as-is (it contains the formatted result + Explanation)\n",
    "        add_message('bot', reply)\n",
    "        user_input.value = \"\"\n",
    "        chat_log.layout.overflow_y = 'auto'\n",
    "    finally:\n",
    "        send_btn.disabled = False\n",
    "\n",
    "def handle_clear(_):\n",
    "    chat_log.children = ()\n",
    "\n",
    "send_btn.on_click(handle_send)\n",
    "clear_btn.on_click(handle_clear)\n",
    "\n",
    "display(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
